{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b86bd9-736c-42c2-ba6d-f43bb0b6401c",
   "metadata": {},
   "source": [
    "## Q1. Explain the difference between linear regression and logistic regression models. Provide an example of a scenario where logistic regression would be more appropriate.\n",
    "\n",
    "### Difference:\n",
    "1. **Linear Regression**: \n",
    "   - Predicts a continuous dependent variable.\n",
    "   - Uses a straight-line equation (`y = mx + c`) to model the relationship between features and the target.\n",
    "   - Example: Predicting house prices based on area and location.\n",
    "\n",
    "2. **Logistic Regression**:\n",
    "   - Predicts a categorical dependent variable (e.g., binary classification).\n",
    "   - Uses a sigmoid function to model the probability of belonging to a class.\n",
    "   - Example: Predicting whether an email is spam or not (binary: spam/not spam).\n",
    "\n",
    "### Scenario for Logistic Regression:\n",
    "Logistic regression is more appropriate when the target variable is categorical. For example:\n",
    "- **Scenario**: Predicting whether a customer will churn (yes/no).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e940f3d-5c30-44cd-be5e-3b7a1ffc42e5",
   "metadata": {},
   "source": [
    "## Q2. What is the cost function used in logistic regression, and how is it optimized?\n",
    "\n",
    "### Cost Function:\n",
    "The cost function used in logistic regression is **log-loss** (also called cross-entropy loss):\n",
    "\\[\n",
    "J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y_i \\log(h_\\theta(x_i)) + (1 - y_i) \\log(1 - h_\\theta(x_i)) \\right]\n",
    "\\]\n",
    "- \\( y_i \\): Actual class label (0 or 1).\n",
    "- \\( h_\\theta(x_i) \\): Predicted probability.\n",
    "\n",
    "### Optimization:\n",
    "- The cost function is optimized using **gradient descent** or its variants (e.g., stochastic gradient descent, mini-batch gradient descent).\n",
    "- The algorithm iteratively adjusts model parameters to minimize the cost function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ae86c-4060-43a9-9858-d36976865586",
   "metadata": {},
   "source": [
    "## Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting.\n",
    "\n",
    "### Regularization:\n",
    "- Adds a penalty term to the cost function to discourage large coefficients, preventing overfitting.\n",
    "- **Types**:\n",
    "  1. **L1 Regularization** (Lasso): Adds the absolute values of coefficients (\\(\\| \\theta \\|_1\\)).\n",
    "  2. **L2 Regularization** (Ridge): Adds the square of coefficients (\\(\\| \\theta \\|_2^2\\)).\n",
    "\n",
    "### Modified Cost Function:\n",
    "For L2 regularization:\n",
    "\\[\n",
    "J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y_i \\log(h_\\theta(x_i)) + (1 - y_i) \\log(1 - h_\\theta(x_i)) \\right] + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j^2\n",
    "\\]\n",
    "- \\( \\lambda \\): Regularization strength.\n",
    "\n",
    "### Benefit:\n",
    "- Prevents overfitting by reducing model complexity.\n",
    "- Improves generalization to unseen data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead99269-b56b-42f7-912a-96dd8cb3683b",
   "metadata": {},
   "source": [
    "## Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression model?\n",
    "\n",
    "### ROC Curve:\n",
    "- Stands for **Receiver Operating Characteristic** curve.\n",
    "- Plots **True Positive Rate (TPR)** against **False Positive Rate (FPR)** at various threshold levels.\n",
    "- TPR (sensitivity): \\( \\frac{\\text{True Positives}}{\\text{True Positives + False Negatives}} \\)\n",
    "- FPR: \\( \\frac{\\text{False Positives}}{\\text{False Positives + True Negatives}} \\)\n",
    "\n",
    "### Usage:\n",
    "- Evaluates the model's ability to distinguish between classes.\n",
    "- **Area Under the Curve (AUC)**: Measures overall performance.\n",
    "  - AUC = 1: Perfect model.\n",
    "  - AUC = 0.5: Random guess.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7968c1e-ba18-4997-bb2a-230bafa58bcf",
   "metadata": {},
   "source": [
    "## Q5. What are some common techniques for feature selection in logistic regression? How do these techniques help improve the model's performance?\n",
    "\n",
    "### Techniques:\n",
    "1. **Recursive Feature Elimination (RFE)**:\n",
    "   - Iteratively removes least important features based on model performance.\n",
    "2. **Regularization (L1 Penalty)**:\n",
    "   - Automatically selects important features by shrinking irrelevant coefficients to zero.\n",
    "3. **Statistical Tests**:\n",
    "   - Use methods like chi-square tests or ANOVA to identify significant features.\n",
    "4. **Variance Threshold**:\n",
    "   - Removes low-variance features.\n",
    "5. **Correlation Analysis**:\n",
    "   - Removes highly correlated features to reduce multicollinearity.\n",
    "\n",
    "### Benefit:\n",
    "- Reduces overfitting.\n",
    "- Improves model interpretability and computational efficiency.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de8025-8bdc-4eee-b4e5-e45f911356ca",
   "metadata": {},
   "source": [
    "## Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing with class imbalance?\n",
    "\n",
    "### Strategies:\n",
    "1. **Resampling Techniques**:\n",
    "   - Oversampling the minority class (e.g., SMOTE).\n",
    "   - Undersampling the majority class.\n",
    "2. **Class Weight Adjustment**:\n",
    "   - Adjust weights to penalize misclassification of the minority class.\n",
    "3. **Synthetic Data Generation**:\n",
    "   - Create synthetic samples for the minority class using techniques like SMOTE.\n",
    "4. **Threshold Tuning**:\n",
    "   - Adjust the decision threshold to balance sensitivity and specificity.\n",
    "5. **Evaluation Metrics**:\n",
    "   - Use metrics like precision, recall, F1-score, and AUC-ROC instead of accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e44c39-93ad-4854-98e9-2f65fd3e13d5",
   "metadata": {},
   "source": [
    "## Q7. Can you discuss some common issues and challenges that may arise when implementing logistic regression, and how they can be addressed? For example, what can be done if there is multicollinearity among the independent variables?\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "1. **Multicollinearity**:\n",
    "   - Causes unstable coefficients.\n",
    "   - Solution: Use **L2 regularization** or **drop highly correlated features**.\n",
    "2. **Overfitting**:\n",
    "   - Occurs when the model is too complex.\n",
    "   - Solution: Apply **regularization** (L1 or L2).\n",
    "3. **Class Imbalance**:\n",
    "   - Leads to biased predictions.\n",
    "   - Solution: Use **resampling techniques** or **adjust class weights**.\n",
    "4. **Non-linear Relationships**:\n",
    "   - Logistic regression assumes linear relationships between features and the log-odds.\n",
    "   - Solution: Use **non-linear transformations** or switch to a more flexible model (e.g., decision trees).\n",
    "5. **Feature Scaling**:\n",
    "   - Large feature values can cause convergence issues.\n",
    "   - Solution: Apply **standardization or normalization**.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
